{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDAE - Movie Recommendation Top-k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as stream:\n",
    "        try:\n",
    "            config = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return config\n",
    "\n",
    "cfg = load_config('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('CUDA is available')\n",
    "    cfg['device'] = True\n",
    "\n",
    "device = torch.device('cuda' if cfg['device'] else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe5fb439590>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(cfg['seed'])\n",
    "np.random.seed(cfg['seed'])\n",
    "torch.manual_seed(cfg['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(cfg['DATA_DIR'], cfg['data']), header=0, usecols=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['user'].nunique()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# train, test = train_test_split(raw_data, test_size=0.2, random_state=cfg['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class CDAEData(data.Dataset):\n",
    "    def __init__(self, data: np.ndarray) -> None:\n",
    "        super(CDAEData, self).__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index) -> None:\n",
    "        return index, self.data[index]\n",
    "\n",
    "def get_count(data: np.ndarray, id: str) -> pd.DataFrame:\n",
    "    r\"\"\"Helper function to get the count of each id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Data which consists of user_id, item_id.\n",
    "\n",
    "    id : str\n",
    "        The name of the id.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The count of each id.\n",
    "    \"\"\"\n",
    "    count_groupby = data[[id]].groupby(id, as_index=False).size()\n",
    "\n",
    "    return count_groupby\n",
    "\n",
    "\n",
    "def preprocess(data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, int, int]:\n",
    "    r\"\"\"Helper function to preprocess data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data which consists of user_id, item_id.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, int, int]\n",
    "    \"\"\"\n",
    "    num_users = data[\"user\"].nunique()\n",
    "    num_items = data[\"item\"].nunique()\n",
    "\n",
    "    user_activity = get_count(data=data, id=\"user\")\n",
    "    item_popularity = get_count(data=data, id=\"item\")\n",
    "\n",
    "    # Shuffle User Indices\n",
    "    unique_uid = user_activity['user'].unique()\n",
    "    unique_sid = item_popularity['item'].unique()\n",
    "\n",
    "    # Indexing\n",
    "    user2id = dict((uid, i) for (i, uid) in enumerate(unique_uid))\n",
    "    item2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "\n",
    "    # # np.random.seed(seed)\n",
    "    # idx_perm = np.random.permutation(unique_uid.size)\n",
    "    # unique_uid = unique_uid[idx_perm]\n",
    "\n",
    "    # # Split Train / Test User\n",
    "    # tr_users = unique_uid[:-3000]\n",
    "    # te_users = unique_uid[-3000:]\n",
    "\n",
    "    # train = data.loc[raw_data['user'].isin(tr_users)]\n",
    "    # test = data.loc[raw_data['user'].isin(te_users)]\n",
    "\n",
    "    # Create a directory to save preprocessed data\n",
    "    pro_dir = os.path.join('pro_sg')\n",
    "\n",
    "    if not os.path.exists(pro_dir):\n",
    "        os.makedirs(pro_dir)\n",
    "\n",
    "    with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "        for sid in unique_sid:\n",
    "            f.write('%s\\n' % sid)\n",
    "\n",
    "    with open(os.path.join(pro_dir, 'unique_uid.txt'), 'w') as f:\n",
    "        for uid in unique_uid:\n",
    "            f.write('%s\\n' % uid)\n",
    "\n",
    "    train = numerize(data, user2id, item2id)\n",
    "    # train = numerize(train, user2id, item2id)\n",
    "    # test = numerize(test, user2id, item2id)\n",
    "\n",
    "    train_mat = _to_matrix(data=train, num_users=num_users, num_items=num_items)\n",
    "    test_mat = _to_matrix(data=train, num_users=num_users, num_items=num_items)\n",
    "\n",
    "    return train_mat, test_mat, num_users, num_items\n",
    "\n",
    "def numerize(\n",
    "        tp: pd.DataFrame,\n",
    "        user2id: dict,\n",
    "        item2id: dict,\n",
    "        ) -> pd.DataFrame:\n",
    "    r\"\"\"Helper function to numerize user and item ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tp : pd.DataFrame\n",
    "        Data which consists of user_id, item_id.\n",
    "\n",
    "    user2id : dict\n",
    "        A dictionary which maps user_id to user index.\n",
    "\n",
    "    item2id : dict\n",
    "        A dictionary which maps item_id to item index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Numerized data.\n",
    "    \"\"\"\n",
    "    uid = tp['user'].apply(lambda x: user2id[x])\n",
    "    sid = tp['item'].apply(lambda x: item2id[x])\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])\n",
    "\n",
    "\n",
    "def _to_matrix(\n",
    "    data: Iterable,\n",
    "    num_users: int = None,\n",
    "    num_items: int = None,\n",
    ") -> np.ndarray:\n",
    "    r\"\"\"Helper function to convert an iterable object into the form of matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Iterable\n",
    "        Movie Lens prepocessed data which consists of user, item.\n",
    "    num_users : int, optional\n",
    "        The number of users, by default None\n",
    "    num_items : int, optional\n",
    "        The number of items, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Rating matrix\n",
    "    \"\"\"\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data = np.array(data, dtype=int)\n",
    "\n",
    "    # initialize a matrix\n",
    "    mat = np.zeros((num_users, num_items))\n",
    "\n",
    "    for user, item in data[['uid', 'sid']].values:\n",
    "        mat[user, item] = 1\n",
    "\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat, test_mat, num_users, num_items = preprocess(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CDAEData(train_mat)\n",
    "test_set = CDAEData(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_set, batch_size=cfg['batch_size'], shuffle=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size=cfg['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDAE(nn.Module):\n",
    "    r\"\"\"Collaborative Denoising Auto-Encoder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_users : int\n",
    "        _description_\n",
    "    num_items : int\n",
    "        _description_\n",
    "    num_hidden_units : int\n",
    "        _description_\n",
    "    corruption_ratio : float\n",
    "        _description_\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Wu, Yao, et al. \"Collaborative denoising auto-encoders for top-n\n",
    "        recommender systems.\" Proceedings of the ninth ACM international\n",
    "        conference on web search and data mining. 2016.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        num_hidden_units: int,\n",
    "        corruption_ratio: float,\n",
    "    ) -> None:\n",
    "        super(CDAE, self).__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_hidden_units = num_hidden_units\n",
    "        self.corruption_ratio = corruption_ratio\n",
    "\n",
    "        # CDAE consists of user embedding, encoder, decoder\n",
    "        self.user_embedding = nn.Embedding(num_users, num_hidden_units)\n",
    "        self.encoder = nn.Linear(num_items, num_hidden_units)\n",
    "        self.decoder = nn.Linear(num_hidden_units, num_items)\n",
    "\n",
    "        # Set to use GPU\n",
    "        self.cuda()\n",
    "\n",
    "    def forward(\n",
    "        self, user_idx: torch.Tensor, matrix: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # Apply corruption\n",
    "        matrix = F.dropout(\n",
    "            matrix, p=self.corruption_ratio, training=self.training\n",
    "        )\n",
    "        encoder = torch.tanh(\n",
    "            self.encoder(matrix) + self.user_embedding(user_idx)\n",
    "        )\n",
    "        return self.decoder(encoder)\n",
    "\n",
    "    def train_one_epoch(\n",
    "        self, train_loader: data.DataLoader, optimizer: optim.Optimizer\n",
    "    ) -> torch.Tensor:\n",
    "        r\"\"\"Train a single epoch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_loader : data.DataLoader\n",
    "            Training data loader\n",
    "        optimizer : optim.Optimizer\n",
    "            An optimizer\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Loss value after training one epoch.\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        # Turn training mode on\n",
    "        self.train()\n",
    "\n",
    "        # By using BCEWithLogitsLoss, the return value of 'forward()' method\n",
    "        # is not using sigmoid function.\n",
    "        loss_f = CDAELoss(model=self, lambda_reg=0.01)\n",
    "\n",
    "        for (indices, input_mat) in train_loader:\n",
    "            indices = indices.cuda()\n",
    "            input_mat = input_mat.float().cuda()\n",
    "            self.zero_grad()\n",
    "\n",
    "            predict_mat = self.forward(user_idx=indices, matrix=input_mat)\n",
    "            batch_loss = loss_f(input=predict_mat, target=input_mat)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += batch_loss\n",
    "\n",
    "        return loss / len(train_loader)\n",
    "\n",
    "    def predict(self, train_loader: data.DataLoader) -> np.ndarray:\n",
    "        r\"\"\"Predict items per users.\n",
    "        Observations that already seen by each user are masked with `-inf`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_loader : data.DataLoader\n",
    "            Training data loader\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Prediction matrix which of dimension is same as training data.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            preds = np.zeros_like(train_loader.dataset.data)\n",
    "\n",
    "            for (indices, input_mat) in train_loader:\n",
    "                indices = indices.cuda()\n",
    "                input_mat = input_mat.float().cuda()\n",
    "                batch_pred = torch.sigmoid(self.forward(indices, input_mat))\n",
    "                batch_pred = batch_pred.masked_fill(\n",
    "                    input_mat.bool(), float(\"-inf\")\n",
    "                )\n",
    "\n",
    "                indices = indices.detach().cpu().numpy()\n",
    "                preds[indices] = batch_pred.detach().cpu().numpy()\n",
    "\n",
    "        return preds\n",
    "\n",
    "class CDAELoss(nn.Module):\n",
    "    def __init__(self, model: nn.Module, lambda_reg=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the CDAE loss module with L2 regularization.\n",
    "\n",
    "        Parameters:\n",
    "        - model: The CDAE model instance to apply regularization.\n",
    "        - lambda_reg: Regularization strength.\n",
    "        \"\"\"\n",
    "        super(CDAELoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.bce_with_logits_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \"\"\"\n",
    "        Compute the CDAE loss as the sum of BCE loss and L2 regularization.\n",
    "\n",
    "        Parameters:\n",
    "        - input: The predicted values from the CDAE.\n",
    "        - target: The true values (actual user-item interactions).\n",
    "\n",
    "        Returns:\n",
    "        - The computed loss value.\n",
    "        \"\"\"\n",
    "        # Compute the binary cross-entropy loss\n",
    "        bce_loss = self.bce_with_logits_loss(input, target)\n",
    "\n",
    "        # Compute the L2 regularization term\n",
    "        l2_reg = torch.tensor(0.).cuda()\n",
    "        for param in self.model.parameters():\n",
    "            l2_reg += torch.norm(param)**2\n",
    "        l2_reg_loss = self.lambda_reg * l2_reg\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = bce_loss + l2_reg_loss\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CDAE(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    num_hidden_units=cfg['num_hidden_units'],\n",
    "    corruption_ratio=cfg['corruption_ratio'],\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:02<03:18,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]:: Loss: 113995.3515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:04<02:38,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1]:: Loss: 93897.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [00:05<02:26,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2]:: Loss: 77537.8828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [00:07<02:19,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3]:: Loss: 64113.58984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [00:09<02:17,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4]:: Loss: 53045.1484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:11<02:13,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5]:: Loss: 43890.55859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [00:13<02:13,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6]:: Loss: 36303.33203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [00:14<02:09,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7]:: Loss: 30007.07421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [00:16<02:04,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8]:: Loss: 24778.48046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [00:18<02:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9]:: Loss: 20435.57421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [00:20<02:03,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10]:: Loss: 16828.98828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [00:22<02:03,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11]:: Loss: 13835.4970703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [00:23<02:03,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12]:: Loss: 11352.962890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [00:25<02:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13]:: Loss: 9296.48046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [00:27<02:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14]:: Loss: 7595.28857421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 16/80 [00:29<01:57,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15]:: Loss: 6190.28466796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [00:31<01:56,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16]:: Loss: 5032.04541015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 18/80 [00:33<01:52,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17]:: Loss: 4079.205322265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/80 [00:34<01:50,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18]:: Loss: 3297.117431640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/80 [00:36<01:47,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19]:: Loss: 2656.76953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 21/80 [00:38<01:45,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20]:: Loss: 2133.874267578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:40<01:45,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21]:: Loss: 1708.106689453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [00:42<01:43,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22]:: Loss: 1362.4794921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [00:43<01:40,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23]:: Loss: 1082.8116455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [00:45<01:36,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24]:: Loss: 857.2839965820312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 26/80 [00:47<01:33,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25]:: Loss: 676.0653686523438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [00:49<01:33,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26]:: Loss: 530.9949951171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/80 [00:50<01:32,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27]:: Loss: 415.3156433105469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [00:52<01:29,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28]:: Loss: 323.4482421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/80 [00:54<01:26,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29]:: Loss: 250.8002471923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/80 [00:56<01:26,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30]:: Loss: 193.60238647460938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 32/80 [00:57<01:24,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31]:: Loss: 148.77346801757812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [00:59<01:22,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32]:: Loss: 113.80338287353516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 34/80 [01:01<01:20,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33]:: Loss: 86.65589141845703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/80 [01:03<01:19,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34]:: Loss: 65.6859130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 36/80 [01:04<01:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35]:: Loss: 49.57046890258789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 37/80 [01:06<01:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36]:: Loss: 37.25102615356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/80 [01:08<01:14,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37]:: Loss: 27.883724212646484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [01:10<01:13,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38]:: Loss: 20.800626754760742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 40/80 [01:12<01:11,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39]:: Loss: 15.475110054016113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 41/80 [01:13<01:09,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40]:: Loss: 11.493955612182617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [01:15<01:08,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41]:: Loss: 8.535489082336426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [01:17<01:06,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42]:: Loss: 6.350606918334961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 44/80 [01:19<01:04,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43]:: Loss: 4.746762275695801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 45/80 [01:21<01:02,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44]:: Loss: 3.5771305561065674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 46/80 [01:22<01:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45]:: Loss: 2.730046510696411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/80 [01:24<00:59,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46]:: Loss: 2.1202964782714844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 48/80 [01:26<00:57,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47]:: Loss: 1.6846855878829956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 49/80 [01:28<00:55,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48]:: Loss: 1.3758313655853271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 50/80 [01:29<00:53,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49]:: Loss: 1.1582449674606323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 51/80 [01:31<00:51,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50]:: Loss: 1.0063291788101196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 52/80 [01:33<00:50,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51]:: Loss: 0.901112973690033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 53/80 [01:35<00:47,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52]:: Loss: 0.828715443611145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/80 [01:37<00:46,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53]:: Loss: 0.7794148325920105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 55/80 [01:38<00:44,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54]:: Loss: 0.7460851669311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 56/80 [01:40<00:42,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55]:: Loss: 0.7237800359725952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 57/80 [01:42<00:41,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56]:: Loss: 0.7089977264404297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 58/80 [01:44<00:40,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57]:: Loss: 0.699174702167511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 59/80 [01:46<00:38,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58]:: Loss: 0.6928858160972595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 60/80 [01:47<00:36,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59]:: Loss: 0.6888647079467773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [01:49<00:34,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60]:: Loss: 0.6861808896064758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [01:51<00:31,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61]:: Loss: 0.6845281720161438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [01:53<00:30,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62]:: Loss: 0.6834279894828796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 64/80 [01:55<00:28,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63]:: Loss: 0.6828171014785767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 65/80 [01:56<00:26,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64]:: Loss: 0.682465672492981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 66/80 [01:58<00:25,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65]:: Loss: 0.6822625398635864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 67/80 [02:00<00:23,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66]:: Loss: 0.6821296811103821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 68/80 [02:02<00:21,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 67]:: Loss: 0.6820774674415588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 69/80 [02:04<00:19,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68]:: Loss: 0.6819056868553162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 70/80 [02:05<00:17,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69]:: Loss: 0.6819186210632324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 71/80 [02:07<00:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70]:: Loss: 0.6819902658462524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 72/80 [02:09<00:14,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71]:: Loss: 0.6818622946739197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 73/80 [02:11<00:12,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72]:: Loss: 0.6820031404495239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 74/80 [02:12<00:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73]:: Loss: 0.6819106936454773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 75/80 [02:14<00:09,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74]:: Loss: 0.6819629669189453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 76/80 [02:16<00:07,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75]:: Loss: 0.681944727897644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 77/80 [02:18<00:05,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76]:: Loss: 0.6819998025894165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 78/80 [02:20<00:03,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77]:: Loss: 0.6819154024124146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [02:22<00:01,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 78]:: Loss: 0.6819136738777161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [02:23<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 79]:: Loss: 0.6818909645080566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(cfg['n_epochs'])):\n",
    "        loss = model.train_one_epoch(train_loader, optimizer)\n",
    "        print(f\"[Epoch {epoch}]:: Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual: np.ndarray, pred: np.ndarray, top_k: int) -> float:\n",
    "    r\"\"\"_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.ndarray\n",
    "        _description_\n",
    "    pred : np.ndarray\n",
    "        _description_\n",
    "    top_k : int\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    actual = np.asarray(actual).astype(np.bool)\n",
    "\n",
    "    # Get indices of the top_k predicted scores\n",
    "    top_k_pred_indices = np.argsort(pred)[-top_k:]\n",
    "\n",
    "    # Create a binary array of the same shape as actual, where only the top k predictions are True\n",
    "    top_k_preds = np.zeros_like(pred, dtype=np.bool)\n",
    "    top_k_preds[top_k_pred_indices] = True\n",
    "\n",
    "    # Calculate the number of relevant items retrieved in the top k predictions\n",
    "    relevant_and_retrieved = np.sum(actual & top_k_preds)\n",
    "\n",
    "    # Calculate the total number of relevant items\n",
    "    total_relevant = np.sum(actual)\n",
    "\n",
    "    # Handle the case where there are no relevant items\n",
    "    if total_relevant == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = relevant_and_retrieved / total_relevant\n",
    "\n",
    "    return recall\n",
    "\n",
    "def map_at_k(actual: np.ndarray, pred: np.ndarray, top_k: int) -> float:\n",
    "    r\"\"\"Mean average precision at k.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.ndarray\n",
    "        A matrix with actual values.\n",
    "    pred : np.ndarray\n",
    "        A matrix with predictions.\n",
    "    top_k : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Mean average precision at k\n",
    "    \"\"\"\n",
    "    if not _assert_same_dimension(actual, pred):\n",
    "        raise AssertionError(\"Two input matrices should have same dimension.\")\n",
    "\n",
    "    map_ = 0\n",
    "\n",
    "    num_users = len(pred)\n",
    "    top_k_items = _topk(input=pred, k=top_k)\n",
    "\n",
    "    for i in range(num_users):\n",
    "        actual_item = set(actual[i].nonzero()[0])\n",
    "        pred_item = top_k_items[i]\n",
    "\n",
    "        map_ += _ap_at_k(actual=actual_item, pred=pred_item, top_k=top_k)\n",
    "\n",
    "    return map_ / num_users\n",
    "\n",
    "def _ap_at_k(actual: np.array, pred: np.array, top_k: int) -> float:\n",
    "    r\"\"\"Avearge precision at k\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.array\n",
    "        A list of item are to be predicted\n",
    "    pred : np.array\n",
    "        A list of predicted items\n",
    "    top_k : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Average precision at k\n",
    "    \"\"\"\n",
    "\n",
    "    if len(pred) > top_k:\n",
    "        pred = pred[:top_k]\n",
    "\n",
    "    p, cnt = 0, 0\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    for idx, item in enumerate(pred):\n",
    "        if item in actual:\n",
    "            cnt += 1\n",
    "            p += cnt / (idx + 1)\n",
    "\n",
    "    return 0.0 if cnt == 0 else p / min(top_k, len(actual))\n",
    "\n",
    "def _topk(input: np.ndarray, k: int) -> np.ndarray:\n",
    "    r\"\"\"Returns indices of k largest element of the given input matrix along\n",
    "    the horizontal axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : np.ndarray\n",
    "        _description_\n",
    "    k : int\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    return np.argsort(input)[:, -k:][:, ::-1]\n",
    "\n",
    "def _assert_same_dimension(actual: np.ndarray, pred: np.ndarray) -> bool:\n",
    "    r\"\"\"Check the actual matrix and the prediction have same dimension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.ndarray\n",
    "        Actual values\n",
    "    pred : np.ndarray\n",
    "        Predicted values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "    \"\"\"\n",
    "    return actual.shape == pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.000000\n"
     ]
    }
   ],
   "source": [
    "eval_result = map_at_k(actual=test_mat, pred=preds, top_k=10)\n",
    "\n",
    "print(f\"MAP@10: {eval_result:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_420536/2323554715.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  actual = np.asarray(actual).astype(np.bool)\n",
      "/tmp/ipykernel_420536/2323554715.py:24: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  top_k_preds = np.zeros_like(pred, dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL@10: 0.219061\n"
     ]
    }
   ],
   "source": [
    "eval_result = recall_at_k(actual=test_mat, pred=preds, top_k=10)\n",
    "\n",
    "print(f\"RECALL@10: {eval_result:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchedm=raw_data.groupby('user')['item'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "11        [4643, 170, 531, 616, 2140, 2722, 2313, 2688, ...\n",
       "14        [8961, 1396, 471, 2105, 1042, 1947, 1269, 2394...\n",
       "18        [1952, 1283, 3507, 4280, 51084, 593, 318, 356,...\n",
       "25        [261, 22, 2161, 3255, 372, 1093, 428, 175, 214...\n",
       "31        [260, 1196, 1210, 7153, 4993, 5952, 1270, 5855...\n",
       "                                ...                        \n",
       "138473    [524, 3354, 1025, 6565, 69757, 2085, 32, 55282...\n",
       "138475    [1639, 1673, 1148, 246, 2019, 1267, 1172, 1235...\n",
       "138486    [2694, 1994, 2723, 441, 2288, 637, 2013, 2423,...\n",
       "138492    [2115, 908, 58, 2700, 2599, 1500, 1358, 1288, ...\n",
       "138493    [3174, 2872, 48780, 2662, 2840, 1566, 2857, 20...\n",
       "Name: item, Length: 31360, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watchedm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid = pd.read_csv(os.path.join('pro_sg/unique_sid.txt'),sep=\" \",header=None)\n",
    "unique_uid = pd.read_csv(os.path.join('pro_sg/unique_uid.txt'),sep=\" \",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2show = dict((i, sid) for (i, sid) in enumerate(unique_sid.squeeze()))\n",
    "id2profile = dict((i, pid) for (i, pid) in enumerate(unique_uid.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(preds)\n",
    "\n",
    "column=list(temp.columns)\n",
    "origin_mid=[id2show[x] for x in column]\n",
    "\n",
    "row=list(temp.index)\n",
    "origin_uid=[id2profile[x] for x in row]\n",
    "\n",
    "temp.columns=origin_mid\n",
    "temp.index=origin_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [01:02<00:00, 499.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "sumbission=dict()\n",
    "sumbission={'user': [],'item': []}\n",
    "sumbission\n",
    "\n",
    "for row in tqdm(temp.iterrows(),total=31360):\n",
    "    userid=row[0]\n",
    "    movies=row[1]\n",
    "    watchedmovies=watchedm.get(userid, [])\n",
    "\n",
    "    for _ in range(10):\n",
    "        sumbission['user'].append(userid)\n",
    "\n",
    "    itemp=[]\n",
    "    for movie in reversed(list(movies.sort_values().index)):\n",
    "        if len(itemp)==10:\n",
    "            break\n",
    "        else:\n",
    "            if movie not in watchedmovies:\n",
    "                itemp.append(movie)\n",
    "\n",
    "    sumbission['item']+=itemp\n",
    "\n",
    "sumbission=pd.DataFrame(sumbission)\n",
    "sumbission.sort_values('user', inplace=True)\n",
    "sumbission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
